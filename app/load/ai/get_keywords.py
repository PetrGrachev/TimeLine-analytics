from keybert import KeyBERT
import logging
import nltk
from nltk.corpus import stopwords

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∏–º —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
try:
    russian_stopwords = stopwords.words("russian")
except LookupError:
    nltk.download("stopwords")
    russian_stopwords = stopwords.words("russian")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å –æ—Ç Sentence Transformers (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π)
kw_model = KeyBERT(model="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

def get_keywords(feedback_texts, top_n=10):
    try:
        combined_text = " ".join(feedback_texts)

        logger.info(f"üí¨ –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–æ–≤: {combined_text[:200]}...")

        keywords = kw_model.extract_keywords(
            combined_text,
            keyphrase_ngram_range=(1, 3),
            stop_words=russian_stopwords,
            top_n=top_n,
            use_maxsum=True,
            nr_candidates=20
        )

        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑: {keywords}")

        # –£—Å–ª–æ–≤–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî –ø–µ—Ä–≤—ã–µ top_n//2 –∫–∞–∫ positive, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞–∫ negative
        positive_keywords = [{"phrase": phrase, "score": score} for phrase, score in keywords[:top_n//2]]
        negative_keywords = [{"phrase": phrase, "score": score} for phrase, score in keywords[top_n//2:]]

        return {
            "positive_keywords": positive_keywords,
            "negative_keywords": negative_keywords
        }

    except Exception as e:
        logger.exception("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑:")
        return {"positive_keywords": [], "negative_keywords": []}
